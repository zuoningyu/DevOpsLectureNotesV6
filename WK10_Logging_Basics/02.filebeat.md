# Integrate the ELK with filebeat

![Alt text](images/high_level.png?raw=true)
reference: https://www.freecodecamp.org/news/docker-container-log-analysis-with-elastic-stack-53d5ec9e5953/

## Step 1. Let us fix something in docker-elk repo
Go to the docker-elk folder that you cloned (mentioned in 01.elk_hands_on.md)
```
cd docker-elk
```
Open logstash -> pipeline -> logstash.conf and add 
```
index => "%{[@metadata][beat]}-%{[@metadata][version]}"
```
on line 18 
```
...
output {
	elasticsearch {
		hosts => "elasticsearch:9200"
		user => "elastic"
		password => "changeme"
		index => "%{[@metadata][beat]}-%{[@metadata][version]}"
	}
}
```
This is to index the logs that are sent from filebeats
## Step 2. Rebuild and run the docker-compose
```
docker-compose build
docker-compose up
```
In another window, type 
```
docker-compose ps
```
You should see
```
           Name                         Command               State                                               Ports                                             
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
docker-elk_elasticsearch_1   /bin/tini -- /usr/local/bi ...   Up      0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp                                                
docker-elk_kibana_1          /bin/tini -- /usr/local/bi ...   Up      0.0.0.0:5601->5601/tcp                                                                        
docker-elk_logstash_1        /usr/local/bin/docker-entr ...   Up      0.0.0.0:5000->5000/tcp, 0.0.0.0:5000->5000/udp, 0.0.0.0:5044->5044/tcp, 0.0.0.0:9600->9600/tcp

```



## Step 3. Let us build the filebeat docker container
```
cd filebeat
docker build -t fcc/filebeat .
```
Build the docker image

## Step 4. Run the filebeat agent to collect docker logs
Run filebeat with the following command to collect docker logs 

```
docker run -v '/var/lib/docker/containers:/usr/share/dockerlogs/data:ro' -v '/var/run/docker.sock:/var/run/docker.sock' --name filebeat fcc/filebeat:latest
```

In the above Docker command, note the two bind mount parameters: /var/lib/docker/containers is the path where docker 
logs exist within the host machine, and it has been bound to /usr/share/dockerlogs/data path within Filebeat container
with read only access.

In the second bind mount argument, /var/run/docker.sock is bound into the Filebeat containerâ€™s Docker daemon. 
It is the unix socket the Docker daemon listens on by default and it can be used to communicate with the daemon 
from within a container. This allows our Filebeat container to obtain Docker metadata and enrich the container log 
entries along with the metadata and push it to ELK stack.

## Step 5. login to kibana and create index
Login to Kibana with username:elastic and password: changeme

Go to `http://localhost:5601/app/discover` you will not see filebeat index patterns but the old ones only.

This is because we haven't created one.

Now let us go to `http://localhost:5601/app/management` or stack management

![Alt text](images/create_index_pattern.png?raw=true)

create an index pattern with a name:

![Alt text](images/define_index_pattern.png?raw=true)

click next step and next step.

## Step 6. Viola! Let us check the docker logs
You should see the following in `http://localhost:5601/app/discover` 
![Alt text](images/docker_logs.png?raw=true)


## Homework
Filebeat has been evolved and can replace logstash to some extent.
![Alt text](images/evo.png?raw=true)

Could you follow the guide and try this different setup? 
https://medium.com/@bcoste/powerful-logging-with-docker-filebeat-and-elasticsearch-8ad021aecd87

Once you have done the above practice, you should be able to set up logging for EasyCRM. Try it out and see how you go. 