##


## PYTHON LOGGING LEVELS
There are six log levels in Python; each level is associated with an integer that indicates the log severity: 
* NOTSET=0, 
* DEBUG=10, 
* INFO=20, 
* WARN=30, 
* ERROR=40,
* CRITICAL=50.

## Ways to log
1. Logging to Standard Output for Systemd
2. The alternative is to send it directly to syslog. This is great for older operating systems that don’t have systemd.
3. The final option is to log messages directly to a file.

## Python Components for Logging
### Log formatter
Formatting is important to machines to understand 

For example, when a log “hello world” is sent through a log formatter:
```
"%(asctime)s — %(name)s — %(levelname)s — %(funcName)s:%(lineno)d — %(message)s"
```
it will become
```
2018-02-07 19:47:41,864 - a.b.c - WARNING - <module>:1 - hello world
```

### Log handler
As the name suggested, this component is for developers to decide how to handle the data:
* Display/Write in the console (via StreamHandler)
* Display/Write in a file (via FileHandler)
* And many more ...

## Hands-on
Now, let us add logging in the console and in a file to our `flask_statsd_prometheus`

### Step 1. Create a logger file
Create a file under `flask_statsd_prometheus/src` and call it `my_logger.py`
and copy/paste in the following:
```
import logging
import sys
from logging.handlers import TimedRotatingFileHandler


FORMATTER = logging.Formatter("%(asctime)s — %(name)s — %(levelname)s — %(message)s")
LOG_FILE = "my_app.log"


def get_console_handler():
   console_handler = logging.StreamHandler(sys.stdout)
   console_handler.setFormatter(FORMATTER)
   return console_handler

def get_file_handler():
   file_handler = TimedRotatingFileHandler(LOG_FILE, when='midnight')
   file_handler.setFormatter(FORMATTER)
   return file_handler

def get_logger(logger_name):
   logger = logging.getLogger(logger_name)
   logger.setLevel(logging.DEBUG) # better to have too much log than not enough
   logger.addHandler(get_console_handler())
   logger.addHandler(get_file_handler())
   # with this pattern, it's rarely necessary to propagate the error up to parent
   logger.propagate = False
   return logger
```
Now, we have a logger that can log to a file and log to console

### Step 2. Introduce the logger to your main program

Add logger to your main program by openning `flask_app.py`
and add the following lines at the top
```
from my_logger import get_logger
log = get_logger(__name__)
```
and then to each function add either log.info or log.error
```
@app.route('/test/')
def test():
    log.info('hitting /test/ endpoint')
    return 'rest'
```

```
@app.errorhandler(500)
def handle_500(error):
    log.error(f'something went wrong {error}')
    return str(error), 500
```

### Step 3. Now let us try it out

You can either run it locally by 
```
python flask_app.py
```
or build and run via docker-compose.

Before proceed, please change 5000 to 5001 port `dockerfile` and `docker-compose.yml`
Because ELK is using 5000

Also, we need to change `flask_app.py` the last line to:
```
if __name__ == '__main__':
    app.run(port=5001)
```
After changing, run:
```
docker build -t jr/flask_app_statsd .
docker-compose -f docker-compose.yml
```



### Step 4. Figure out the problems
Now, when you hit `localhost:5001/test1`
You should be able to see this in your console
```
2021-10-26 10:17:35,098 — flask_app — ERROR — something went wrong division by zero
```
and a `my_app.log` in your `flask_statsd_prometheus/src` folder

If you run docker you should run 
```
docker exec -it webapp ls
```
to see the `my_app.log` file

But the stacktrace
```
Traceback (most recent call last):
  File "flask_app.py", line 22, in test1
    1/0
ZeroDivisionError: division by zero
```
is not there in the `my_app.log` file and not logged by logger

It is really important to log this info for debugging purpose as it points out the faulty file and the line no

### Step 5. Wrap around with try except to catch stacktrace
To log the stack trace, wrap the most fragile function with try except
and raise the exception to its parent function. You should write something like:
```
@app.route('/test1/')
def test1():
    log.info('hitting /test1/ endpoint')
    try:
        1/0
    except Exception as e:
        log.exception(e)
        raise
    return 'rest'
```

Now, rebuild or rerun and you should see the stacktrace get logged to the file and the console
```
2021-10-25 22:36:49,676 — __main__ — ERROR — division by zero
Traceback (most recent call last):
File "flask_app.py", line 22, in test1
1/0
ZeroDivisionError: division by zero
```
However, it is still not good enough, because it is in multiple lines and would require extra filters to be
written in filebeat. How do we turn it into one-liner?

## Step 6. Turn all logs into one liner
To be able to present the data better, we do need to add some logics back to the `my_logger.py`:
```
class OneLineExceptionFormatter(logging.Formatter):
    def formatException(self, exc_info):
        result = super().formatException(exc_info)
        return repr(result)  # The repr() function returns a printable representation of the given object

    def format(self, record):
        result = super().format(record)
        if record.exc_text:
            result = result.replace("\n", "")
        return result
```

And modify the my_logger.py file so it looks like 
```
import logging
import sys
from logging.handlers import TimedRotatingFileHandler

LOG_FILE = "my_app.log"


class OneLineExceptionFormatter(logging.Formatter):
    def formatException(self, exc_info):
        result = super().formatException(exc_info)
        return repr(result)  # The repr() function returns a printable representation of the given object

    def format(self, record):
        result = super().format(record)
        if record.exc_text:
            result = result.replace("\n", "")
        return result


def get_console_handler(formatter):
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    return console_handler


def get_file_handler(formatter):
    file_handler = TimedRotatingFileHandler(LOG_FILE, when='midnight')
    file_handler.setFormatter(formatter)
    return file_handler


def get_logger(logger_name):
    logger = logging.getLogger(logger_name)
    logger.setLevel(logging.DEBUG)  # better to have too much log than not enough in dev/staging
    one_line_formatter = OneLineExceptionFormatter("%(asctime)s — %(name)s — %(levelname)s — %(message)s")
    logger.addHandler(get_console_handler(one_line_formatter))
    logger.addHandler(get_file_handler(one_line_formatter))
    # with this pattern, it's rarely necessary to propagate the error up to parent
    logger.propagate = False
    return logger
```

Whenever we `addHandler`, we will get the handler to do `one_line_formatter` first.

Now, build and/or rerun, you should see something like this:
```
2021-10-25 22:44:00,039 — __main__ — INFO — hitting /test1/ endpoint
2021-10-25 22:44:00,039 — __main__ — ERROR — division by zero'Traceback (most recent call last):\n  File "flask_app.py", line 22, in test1\n    1/0\nZeroDivisionError: division by zero'
2021-10-25 22:44:00,045 — __main__ — ERROR — something went wrong division by zero
```

Viola, we now have proper logging for our webapp. 

## Step 7. Send logs to Kibana
Spin up your app or container
```
cd flask_statsd_prometheus
docker build -t jr/flask_app_statsd .
docker-compose -f docker-compose.yml
```
Now, you should have filebeat, ELK and your app up and running
```
docker ps
CONTAINER ID   IMAGE                      COMMAND                  CREATED          STATUS          PORTS                                                                                                                                                                        NAMES
3c5709600cb9   fcc/filebeat:latest        "/usr/local/bin/dock…"   8 minutes ago    Up 7 minutes                                                                                                                                                                                 filebeat
4f3eca24138d   jr/flask_app_statsd        "/bin/sh -c 'uwsgi -…"   40 minutes ago   Up 40 minutes   0.0.0.0:5001->5001/tcp, :::5001->5001/tcp                                                                                                                                    webapp
7caf66c5c07b   docker-elk_kibana          "/bin/tini -- /usr/l…"   58 minutes ago   Up 58 minutes   0.0.0.0:5601->5601/tcp, :::5601->5601/tcp                                                                                                                                    docker-elk_kibana_1
bd80a6313542   docker-elk_logstash        "/usr/local/bin/dock…"   58 minutes ago   Up 58 minutes   0.0.0.0:5000->5000/tcp, :::5000->5000/tcp, 0.0.0.0:5044->5044/tcp, :::5044->5044/tcp, 0.0.0.0:9600->9600/tcp, 0.0.0.0:5000->5000/udp, :::9600->9600/tcp, :::5000->5000/udp   docker-elk_logstash_1
e0c1c2045b79   docker-elk_elasticsearch   "/bin/tini -- /usr/l…"   58 minutes ago   Up 58 minutes   0.0.0.0:9200->9200/tcp, :::9200->9200/tcp, 0.0.0.0:9300->9300/tcp, :::9300->9300/tcp                                                                                         docker-elk_elasticsearch_1
```
They are connected like this:
![Alt text](images/high_level.png?raw=true)

You can also use the traffic generator to generate some traffic. 
Now, open the discover tab, you should be able to see your logs on Kibana.


### Homework
Could you figure out how to populate each field from the log message? 
e.g. log_level: ERROR, logger_name: __webapp__ etc