## Metrics and metric types

For our purposes, a __metric__ is an observed value of a certain quantity at a given point in time. The total of number hits on a blog post, the total number of people attending a talk, the number of times the data was not found in the caching system, the number of logged-in users on your website—all are examples of metrics.

They broadly fall into four categories:

### Counters

A counter is a cumulative metric that represents a single monotonically increasing counter whose value can only increase
or be reset to zero on restart. For example, you can use a counter to represent the number of requests served, tasks
completed, or errors.

Consider your personal blog. You just published a post and want to keep an eye on how many hits it gets over time, 
a number that can only increase. This is an example of a counter metric. Its value starts at 0 and increases during
 the lifetime of your blog post. Graphically, a counter looks like this:
![Alt text](../images/counter-graph.png?raw=true)

### Gauges
A gauge is a metric that represents a single numerical value that can arbitrarily go up and down.

Gauges are typically used for measured values like temperatures or current memory usage, but also "counts" that can go
 up and down, like the number of concurrent requests.
 
![Alt text](../images/gauge-graph.png?raw=true)
![Alt text](../images/gauge.png?raw=true)
A gauge's value usually has a ceiling and a floor in a certain time window.

### Histograms and timers
A histogram (as Prometheus calls it) or a timer (as StatsD calls it) is a metric to track sampled observations. 
A histogram samples observations (usually things like request durations or response sizes) and counts them in 
configurable buckets. It also provides a sum of all observed values.
![Alt text](../images/histogram-graph.png?raw=true)

A histogram with a base metric name of <basename> exposes multiple time series during a scrape:

* cumulative counters for the observation buckets, exposed as \<basename\>_bucket{le="\<upper inclusive bound\>"}
* the total sum of all observed values, exposed as \<basename\>_sum
* the count of events that have been observed, exposed as \<basename\>_count (identical to \<basename\>_bucket{le="+Inf"}
  above)

Use the histogram_quantile() function to calculate quantiles from histograms or even aggregations of histograms. 
A histogram is also suitable to calculate an Apdex score. When operating on buckets, remember that the histogram is cumulative.
```
http_request_duration_seconds_bucket{le="0.5"} 0
http_request_duration_seconds_bucket{le="1"} 1
http_request_duration_seconds_bucket{le="2"} 2
http_request_duration_seconds_bucket{le="3"} 3
http_request_duration_seconds_bucket{le="5"} 3
http_request_duration_seconds_bucket{le="+Inf"} 3
http_request_duration_seconds_sum 6
http_request_duration_seconds_count 3
```

### Summary
Similar to a histogram, a summary samples observations (usually things like request durations and response sizes). 
While it also provides a total count of observations and a sum of all observed values, it calculates configurable
quantiles over a sliding time window.

A summary with a base metric name of \<basename\> exposes multiple time series during a scrape:
* streaming φ-quantiles (0 ≤ φ ≤ 1) of observed events, exposed as \<basename\>{quantile="<φ>"}
* the total sum of all observed values, exposed as \<basename\>_sum
* the count of events that have been observed, exposed as \<basename\>_count

#### Differences
The essential difference between summaries and histograms is that summaries calculate streaming φ-quantiles on the
client side and expose them directly, while histograms expose bucketed observation counts and the calculation of 
quantiles from the buckets of a histogram happens on the server side using the histogram_quantile() function.


## Common Queries

### Request Count
Return the accumulated request_count with the given app, uri and status labels:
```
request_count{app="apiserver", uri="/api/comments", status~"5.."}
```

### Request Rate (a.k.a Throughput)

Return the per-second rate for all time series with the request_count metric name, as measured over the last 5 minutes:
```
rate(request_count{app="apiserver", uri="/api/comments", status_code=~"5.*"}[5m])
```
Return the 5-minute rate of the request_count metric for the past 30 minutes, with a resolution of 1 minute.
```
rate(request_count{app="apiserver", uri="/api/comments", status_code=~"5.*"}[5m])[30m:1m]
```

Assuming that the request_count time series all have the labels app (fanout by app name) and uri (fanout by
uri of the app), we might want to sum over the rate of all uris, so we get fewer output time series, but
still preserve the app dimension:
```
sum by (app) (
    rate(request_count[5m])
)
```
A typical application use-case to sum up the request rate by status code
```
sum by (status_code) (rate(request_count[5m]))

```


### Error Rate
To calculate the error rate
```
rate(request_count{status_code=~"5.*"}[5m]) / rate(request_count[5m])
```


### Request Duration (a.k.a Response Time)
To calculate the average request duration during the last 5 minutes from a histogram or summary called 
http_request_duration_seconds, use the following expression:
```
  rate(http_request_duration_seconds_sum[5m])
/
  rate(http_request_duration_seconds_count[5m])
```

### Percentile 
To display the request duration within which you have served 95% of requests:
```
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) 
```


### Further Reading
* Wildcard in query? https://prometheus.io/docs/prometheus/latest/querying/basics/
* Some typical promql? https://timber.io/blog/promql-for-humans/
* Apdex? https://prometheus.io/docs/practices/histograms/
