## 





## Error Rate & Throughput
Error Rate
```
sum (rate(request_count{status="500"}[15s])) / sum (rate(request_count[15s]))
```
Total Throughput
```
sum (rate(request_count[15s]))
```
Throughput by API
```
sum by (endpoint) (rate(request_count[15s]))
```
Ref: https://ibm-cloud-architecture.github.io/b2m-nodejs/Prometheus-Grafana/#throughput

## Request Duration
Average Request Duration
```
rate(request_latency_seconds_sum[1m])/rate(request_latency_seconds_count[1m])
```
Or use the percentile in three separate queries
```
request_latency_seconds{quantile="0.5"}
request_latency_seconds{quantile="0.9"}
request_latency_seconds{quantile="0.99"}
```
Ref: https://povilasv.me/prometheus-tracking-request-duration/

## Availability
Availability of your check

You will need to add a `/healthcheck` endpoint in your application and monitor the `/healthcheck` status via the
load balancer.  

## Saturation
### CPU
This is a counter
```
sum by (job) (irate(process_cpu_seconds_total[1m]))
```
https://stackoverflow.com/questions/48916798/monitoring-cpu-utilization-using-prometheus
https://utcc.utoronto.ca/~cks/space/blog/sysadmin/PrometheusRateVsIrate

### Memory
This is a gauge
```
process_resident_memory_bytes/1000/1000
```
### Disk
Leave it as a homework

## Export and redo the terraform step
You now should have a beautiful dashboard like this:
![Alt text](../images/dashboard_ready.png?raw=true)